---
title: "Computational Musicology Portfolio"
author: "Jeev Prayaga"
date: "Block 4"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
    css: styles.scss
    theme: bootstrap
---

```{r setup, include=FALSE}
library(tidyverse)
library(flexdashboard)
library(spotifyr)
library(ggthemes)
library(plotly)
library(compmus)
library(ggpubr)
library(tidymodels)
library(ggdendro)
library(heatmaply)
library(recipes)

corpus <- get_playlist_audio_features("", "14Bfxipb26yzTFoxmDfjeg?si=ff7f24e465794647")


circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

```

### Introduction

A few years ago, I decided to create a new Spotify playlist each month in order to capture my favorite music at various points in time. To keep each playlist consistent, I gave myself the following three conditions:
1. the playlist would contain exactly 11 songs
2. no two songs in the playlist could have the same artist
3. every song in the playlist had to be a song I had listened to during the given calendar month

Between March 2018 and January 2022, I ended up creating 41 monthly playlists, which I have now combined into a single 451-song playlist.

**I think this playlist could serve as a corpus for my portfolio project because it represents the diversity of my music preferences, reflects month-by-month changes in how I listen to music, and reveals long-term trends for how my taste in music may have changed over a period of four years.**

I think the variable of time can be used to create and compare groups of songs. For example, I can compare the valence of songs I added before the COVID-19 pandemic to those I added during lockdown. I can also investigate how different seasons might affect my listening history -- do I listen to more upbeat music in warmer months, or during the winter in an attempt to boost my mood? How has my appreciation for certain artists and genres changed month-by-month and year-by-year?

Since I almost exclusively listen to music on Spotify, I believe this corpus is highly representative of my personal listening habits. I also think the variation in songs will allow me to analyze certain tracks in greater detail. Songs like "2021" by A.G. Cook (a short, digitally-produced electronic track) will contrast greatly with "Obi Agye Me Dofo" by Vis Ã  Vis (a 10-minute Afrobeat track recorded live in the 1970s). These songs fall on different sides of the spectrum in terms of length, genre, and "acousticness," making them good candidates for investigation.

### Has Julian Casablancas' music become more complex over time?
```{r}

tyl <-
  get_tidy_audio_analysis("5KupfEBaVJwL7D2ZN0n1Q1") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      )
  ) %>% 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  )

tyl_plot <- ggplot(tyl,
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "", title = "Keygram for \"Trying Your Luck\" by The Strokes")

mftw <-
  get_tidy_audio_analysis("62JrUht3IRKy4OovuZXfNS") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      )
  ) %>% 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  )

mftw_plot <-  ggplot(mftw,
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "", title = "Keygram for \"My Friend The Walls\" by The Voidz")


figure <- ggarrange(
  tyl_plot, 
  mftw_plot,
  nrow = 2,
  ncol = 1,
  labels = NULL
)
figure

```

***
These two plots represent keygrams for songs from each of Julian Casablancas' two bands: The Strokes and The Voidz. The first track, "Trying Your Luck," comes from The Strokes' 2001 debut album *Is This It*. "My Friend The Walls" is a track on *Virtue*, an album released in 2018 by Casablancas' more experimental side project The Voidz. As a fan of both bands, I wanted to analyze how Casablancas' music has become more experimental by looking at each band's use of key.

When comparing the two keygrams, it is clear that "Trying Your Luck" uses a very consistent key (A minor), shown by the dark blue band that continues throughout the song until the last few seconds. Intuitively, the consistency of the key makes sense, since "Trying Your Luck" is a very simple song with no real change in mood or tone. The same few guitar chords are repeated in the verses and chorus. This was definitely an intentional choice, since much of the popularity of *Is This It* was attributed to its nostalgia-inducing simplicity.

In sharp contrast, "My Friend The Walls" is a complex, constantly shifting song that changes distinctly between each verse and chorus. We can see this on the keygram plot there is a higher level of uncertainty about which key the song is in and evidence of multiple shifts in key. Interestingly, most online sources claim the key of the song is actually G minor. The keygram shows a much more conflicting representation of constant shifts in key, with the most dominant key perhaps being C minor. I think this song exemplifies the more experimental and complex approach to songwriting that Julian Casablancas has developed over the past two decades.

### How do chroma and timbre change during a song?

```{r}
#  (from "https://r-graphics.org/recipe-axes-time-rel")
timeHMS_formatter <- function(x) {
  h <- floor(x / 3600)
  m <- floor((x / 60) %% 60)
  s <- round(x %% 60)                       # Round to nearest second
  lab <- sprintf("%02d:%02d:%02d", h, m, s) # Format the strings as HH:MM:SS
  lab <- sub("^00:", "", lab)               # Remove leading 00: if present
  lab <- sub("^0", "", lab)                 # Remove leading 0 if present
  return(lab)
}

lom <-
  get_tidy_audio_analysis("3IgIofvAq4XuMgIiSTZZQs") %>% # Change URI.
  compmus_align(sections, segments) %>%                     # Change `bars`
  select(sections) %>%                                      #   in all three
  unnest(sections) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "mean", norm = "manhattan"              # Change summary & norm.
      ),
  )

lom_chroma <- lom %>% compmus_self_similarity(pitches, "manhattan")
lom_timbre <- lom %>% compmus_self_similarity(timbre, "manhattan")


chroma_plot <- ggplot(lom_chroma,
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title="Chroma") +
  scale_x_continuous(
    name = "Time",
    breaks = seq(0, 1000, by = 30),
    labels = timeHMS_formatter
  ) +
  scale_y_continuous(
    name = "Time",
    breaks = seq(0, 1000, by = 30),
    labels = timeHMS_formatter
  )

timbre_plot <- ggplot(lom_timbre,
  aes(
    x = xstart + xduration / 2,
    width = xduration,
    y = ystart + yduration / 2,
    height = yduration,
    fill = d
  )
) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title="Timbre") +
  scale_x_continuous(
    name = "Time",
    breaks = seq(0, 1000, by = 30),
    labels = timeHMS_formatter
  ) +
  scale_y_continuous(
    name = "Time",
    breaks = seq(0, 1000, by = 30),
    labels = timeHMS_formatter
  )


bir <-
  get_tidy_audio_analysis("4Cegr1EzzvG8D77lUIsfSK") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "mean", norm = "manhattan"              # Change summary & norm.
      ),
  )

bir_timbre <- bir %>% compmus_gather_timbre()

cepstro_plot <- ggplot(bir_timbre,
  aes(
    x = start + duration / 2,
    width = duration,
    y = basis,
    fill = value
  )
) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title="\"Bir OlasÄ±lÄ±k\" Cepstrogram") +
  scale_fill_viridis_c() +                              
  theme_classic() +
  scale_x_continuous(
    name = "Time",
    breaks = seq(0, 1000, by = 10),
    labels = timeHMS_formatter
  )

figure <- ggarrange(
  cepstro_plot, 
  ggarrange(chroma_plot, timbre_plot, ncol = 2),
  nrow = 2,
  labels = NULL
)
figure

```

***
The top plot is a cepstrogram that visualises the timbre of "Bir OlasÄ±lÄ±k," an instrumental track by Erkin Koray. Since drums are the only instrument in this track, I thought it would be interesting to analyze how timbre changes thruoghout the song. As the plot shows, timbre stays relatively consistent in the C2, C3, and C6 rows, although there are parts in which certain timbres fade into the background or suddenly appear. One notable moment is around the 1:25 minute mark, where there is a bright yellow (high magnitude) section in the C2 row. This correspondes with a drum break that heavily features the cymbal, meaning the C2 timbre might correspond with cymbals or other drum components with similar timbre.

The bottom two plots represent chroma-based and timbre-based self-similarity matrices for the song "Lies of Mercy" by the Durutti Column. This song features a repetitive guitar riff that weaves in and out of the song. This track also has several distinct "sections" that correspond with chord changes. The timbre plot shows large chunks of similarity, since most of the song uses the same guitar and vocals. However, we can clearly see changes in the chroma plot for each of the sections. For example, the 40-second mark represents the change from the first verse to the chorus, and we see this change represented on the plot. There are also chunks of similarity (like the motif from 0:55 to 1:15, which repeats again at 2:05).

### How are valence, energy, loudness, and acousticness related?

```{r}

font <- list(
  family = "Public Sans",
  size = 12,
  color = "white"
)
label <- list(
  bgcolor = "#232F34",
  bordercolor = "transparent",
  font = font
)

p <- ggplot(
  corpus,
  aes(
    x = energy,
    y = valence,
    alpha = loudness,
    size = acousticness,
    name = track.name,
    text = paste(
      "Track: ", track.name,
      "<br>Valence: ", valence,
      "<br>Energy: ", energy,
      "<br>Loudness: ", loudness,
      "<br>Acousticness: ", acousticness
    ))
  ) +
  geom_point(color = "#15a353") +
  scale_size(trans = "reverse") +
  labs(
    title = "Valence, energy, loudness, and acousticness by track",
    x = "Track energy",
    y = "Track valence",
    size = "Track acousticness",
    alpha = "Track loudness"
  ) +
  theme_few()


fig <- ggplotly(p, tooltip = "text") %>%
  style(hoverlabel = label) %>%
  layout(font = font)

fig

```

*** 

This scatterplot maps valence, energy, loudness, and acousticness for every track in the corpus. Using valence and energy on the x- and y-axis respectively, we can see an upward trend showing that higher energy tracks have a higher valence, meaning they are sound more positive to the listener. Using transparency as a fourth variable, we can see that higher energy/valence tracks are also louder, since the darkest points are in the top right quadrant of the plot. Finally, since size represents acousticness on this plot, it is clear that highly acoustic tracks have low valence and energy, since there are very few large points in the top right quadrant.

### How closely do cover songs in different languages align?

```{r}

hier_encore_track <- "4ciRwt5dGHKKm8Et8r1xJ0"
yesterday_track <- "7nSjdcQueimUqsDsBq7orE"

hier_encore <-
  get_tidy_audio_analysis(hier_encore_track) %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

yesterday <-
  get_tidy_audio_analysis(yesterday_track) %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)


compmus_long_distance(
  yesterday %>% mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  hier_encore %>% mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  feature = pitches,
  method = "euclidean"
) %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_equal() +
  labs(title = "Dynamic Time Warping", x = "Yesterday When I Was Young", y = "Hier Encore") +
  scale_fill_viridis_c(guide = NULL)

```

*** 

This plot represents a dynamic time warping between two versions of the famous French chanson "Hier encore." The original version was released in 1964 by Charles Azvanour. Five years later, the American country singer Roy Clark recorded an English version of the song, titled "Yesterday When I Was Young." Since these songs have different lyrics (sung in different languages) and employ different instrumentation, I wanted to investigate how musically similar the two songs really are. This plot shows the chroma features of each song, and similarity is shown by the several faint diagonal lines throughout the song. Although it is clear that the songs are not exactly the same (which would be shown by much clearer diagonal lines that have a slope of 1), we can see some similarities where chords are most likely aligning. Conversely, the parts of the plot where the lines become fragmented or broken probably represent parts of the songs where the chords does not align.

## What makes a live performance unique? {#p-tempo}

As I looked through my corpus, I noticed that although most of my playlists' tracks are studio recordings, I also included a few live versions of my favorite songs. To look for patterns in why I might prefer one over the other, I decided to investigate how musical features might differ between studio and live recordings of the same song. After creating visual representations to compare songs, I found that live versions of songs seem to fall into one of two categories. First, some artists choose to imitate a studio recording when performing live, creating a track that sounds very similar (but perhaps slightly different in timbre) to the original. I think this pattern is clearly shown by examining differences in tempo. For example, the tempograms below show side by side comparisons between the studio recording (on the left) and live recording (on the right) of "Foam" by indie rock band DiviÃ±o Nino.

<div class="row">
  <div>
    <iframe style="border-radius:12px; margin: auto; display: block;" src="https://open.spotify.com/embed/track/1MboJPXUvoSN18XB2nDoBr?utm_source=generator"  height="80" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>
    <figure>
      ```{r, echo=FALSE}
      foam_studio <- get_tidy_audio_analysis("1MboJPXUvoSN18XB2nDoBr")
      foam_studio %>%
        tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) %>%
        ggplot(aes(x = time, y = bpm, fill = power)) +
        geom_raster() +
        scale_fill_viridis_c(guide = "none") +
        labs(x = "Time (s)", y = "Tempo (BPM)") +
        theme_classic()
      ```
    </figure>
  </div>

  <div>
    <iframe style="border-radius:12px; margin: auto; display: block;" src="https://open.spotify.com/embed/track/6rY2KHewC0OF3F22oGZser?utm_source=generator"  height="80" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>
    <figure>
    ```{r, echo=FALSE}
    foam_live <- get_tidy_audio_analysis("6rY2KHewC0OF3F22oGZser")
    foam_live %>%
      tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) %>%
      ggplot(aes(x = time, y = bpm, fill = power)) +
      geom_raster() +
      scale_fill_viridis_c(guide = "none") +
      labs(x = "Time (s)", y = "Tempo (BPM)") +
      theme_classic()
    ```
    </figure>
  </div>
</div>

***

By listening to the songs and examining the tempograms, one can tell that the differences in tempo between both songs are minimal, with only slight fluctuation from 100 BPM. In contrast, some artists intend for their live performances to complement studio recordings by providing a completely different take on the original version. For example, Arctic Monkeys have totally transformed their sound since their debut album, shifting from energetic, punk-inspired rock to slow, jazz-influenced ballads. In 2018, they performed some of their older songs with their newer musical style. Below are two plots comparing the 2006 studio recording of "I Bet You Look Good On The Dancefloor" (on the left) with the 2018 live version (on the right).

<div class="row">
  <div>
    <iframe style="border-radius:12px; margin: auto; display: block;" src="https://open.spotify.com/embed/track/29EkMZmUNz1WsuzaMtVo1i?utm_source=generator" width="100%" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>
    <figure>
    ```{r, echo=FALSE}
    dancefloor_studio <- get_tidy_audio_analysis("29EkMZmUNz1WsuzaMtVo1i")
    dancefloor_studio %>%
      tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) %>%
      ggplot(aes(x = time, y = bpm, fill = power)) +
      geom_raster() +
      scale_fill_viridis_c(guide = "none") +
      labs(x = "Time (s)", y = "Tempo (BPM)") +
      theme_classic()
    ```
    </figure>
  </div>

  <div>
    <iframe style="border-radius:12px; margin: auto; display: block;" src="https://open.spotify.com/embed/track/4YS0QKXLqqSM3MxlWej009?utm_source=generator" width="100%" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>
    <figure>
    ```{r, echo=FALSE}
    dancefloor_live <- get_tidy_audio_analysis("4YS0QKXLqqSM3MxlWej009")
    dancefloor_live %>%
      tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) %>%
      ggplot(aes(x = time, y = bpm, fill = power)) +
      geom_raster() +
      scale_fill_viridis_c(guide = "none") +
      labs(x = "Time (s)", y = "Tempo (BPM)") +
      theme_classic()
    ```
    </figure>
  </div>
</div>


### Can clustering reveal patterns in my lockdown listening preferences?

```{r}

get_conf_mat <- function(fit) {
  outcome <- .get_tune_outcome_names(fit)
  fit %>% 
    collect_predictions() %>% 
    conf_mat(truth = outcome, estimate = .pred_class)
}  

get_pr <- function(fit) {
  fit %>% 
    conf_mat_resampled() %>% 
    group_by(Prediction) %>% mutate(precision = Freq / sum(Freq)) %>% 
    group_by(Truth) %>% mutate(recall = Freq / sum(Freq)) %>% 
    ungroup() %>% filter(Prediction == Truth) %>% 
    select(class = Prediction, precision, recall)
}

may2020 <-
  get_playlist_audio_features("Jeev", "5PgZ3RvjLDoLcWjrnqVsN6") %>%
  add_audio_analysis() %>%
  mutate(
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  ) %>%
  mutate(pitches = map(pitches, compmus_normalise, "clr")) %>%
  mutate_at(vars(pitches, timbre), map, bind_rows) %>%
  unnest(cols = c(pitches, timbre))

may2020_juice <-
  recipe(
    track.name ~
      danceability +
      energy +
      loudness +
      speechiness +
      acousticness +
      instrumentalness +
      liveness +
      valence +
      tempo +
      duration,
    data = may2020
  ) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors()) %>% 
  # step_range(all_predictors()) %>% 
  prep(may2020 %>% mutate(track.name = str_trunc(track.name, 20))) %>%
  juice() %>%
  column_to_rownames("track.name")

may2020_dist <- dist(may2020_juice, method = "euclidean")

may2020_dist %>% 
  hclust(method = "single") %>% # Try single, average, and complete.
  dendro_data() %>%
  ggdendrogram()

heatmaply(
  may2020_juice,
  hclustfun = hclust,
  hclust_method = "average",  # Change for single, average, or complete linkage.
  dist_method = "euclidean"
)

```

***

This plot is a dendrogram of tracks from May 2020 of my corpus. Since these 11 tracks were added to my corpus during one of the most restrictive periods of COVID-19 lockdown, I wanted to see if there are any patterns in my listening history that reflect the slower pace of life while staying at home. This dendrogram uses Euclidean distance and single linkage to show hierarchical clusters of tracks using various Spotify features. Certain features (like duration and tempo) are too general to reflect meaningful patterns in my listening preferences. However, focusing on individual tracks reveals how these features influence clustering. For example, âAshes to Ashesâ and âCastles in the Graveâ are high in tempo and low in acousticness, while âSnowâ and âPlanet Caravanâ are slower, more low-key tracks that share similar valence, energy, and danceability.

